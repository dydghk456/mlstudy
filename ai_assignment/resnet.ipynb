{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 4\n",
        "### Artificial Intelligence, 2022 Fall\n",
        "\n",
        "In this homework we will learn and practice the basics of deep learning by building a deep learning model and training the model by ourselves. With using the PyTorch library, we will implement an image classifier and train with public datasets.\n",
        "\n",
        "We recommend to use Google colab for doing this homework."
      ],
      "metadata": {
        "id": "HIHRj2Qgx0yO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first import the necessary libraries for implementation. "
      ],
      "metadata": {
        "id": "L925PcAfx8z_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH--XczULyu_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    print(\"Please set GPU via Edit -> Notebook Settings.\")\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this homework we are going to use the CIFAR-10 dataset. Using the torchvision library, let's download datasets for training and testing. \n",
        "We first have to convert the images into PyTorch tensors, and normalize them. "
      ],
      "metadata": {
        "id": "X5k6LvIhpGEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_mean=[0.49139968, 0.48215827 ,0.44653124]\n",
        "cifar10_std=[0.24703233, 0.24348505, 0.26158768]\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # for data augmentation\n",
        "    transforms.RandomHorizontalFlip(), # for data augmentation\n",
        "    transforms.ToTensor(),\n",
        "  transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "  transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "nbeAtP0S0-Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyzT_YPWLyvB"
      },
      "source": [
        "Let's visualize some of the images in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC4DqHaMLyvB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def denorm_imgshow(img, mean=cifar10_mean, std=cifar10_std):\n",
        "    mean = np.asarray(mean)\n",
        "    std = np.asarray(std)\n",
        "    denormalize = transforms.Normalize((-1 * mean / std), (1.0 / std))\n",
        "    result_img = img.squeeze(0)\n",
        "    result_img = denormalize(result_img)\n",
        "\n",
        "    # clip image value between 0 and 1\n",
        "    result_img = torch.clamp(result_img, 0, 1)\n",
        "    np_img = result_img.numpy()\n",
        "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "images = images[0:4]\n",
        "labels = labels[0:4]\n",
        "\n",
        "# show images and print labels\n",
        "denorm_imgshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join('%5s\\t' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We checked that data is downloaded properly, and it's time to start implementing our model. In this homework,  we will implement ResNet-50. ResNet is a widely used model, known to solve the vanishing gradient problem which appeared in models with deep network structures, by exploiting residual learning. For detailed explanation, please look up the paper: https://arxiv.org/abs/1512.03385. "
      ],
      "metadata": {
        "id": "iWXIN-1S116_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation\n",
        "ResNet-50 is made up of building blocks called “bottlenecks”. The structure of a building block is as follows:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F9907E0375CB8A11F0F\" width=\"400\"/>\n",
        "</div>\n",
        "\n",
        "First implement a building block by filling in the following skeleton code.\n",
        "\n",
        "- Each weight layer consists of ```conv2d``` - ```batchnorm2d``` - ```relu``` activation\n",
        "- To match the dimension for residual learning, implement and use the ```self.shortcut``` in the skeleton code.\n",
        "- The number 1 and 3 in the figure indicates kernel sizes.\n",
        "- For first and last ```conv2d``` layer, fix the stride to 1. For the second ```conv2d``` layer, stride is determined by input."
      ],
      "metadata": {
        "id": "-aVMcup66SKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, channels, stride=1):\n",
        "        self.expansion = 4\n",
        "        super(Bottleneck, self).__init__()\n",
        "        # TODO\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion*channels:\n",
        "            # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n"
      ],
      "metadata": {
        "id": "ZOYUKTq66nbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the bottleneck block, we will implement ResNet-50 with the blocks. The structure of ResNet-50 is in the following table (3rd column):\n",
        "![table](https://user-images.githubusercontent.com/68190553/117823565-9345b100-b2a8-11eb-8b06-cfbe5511b053.png)\n"
      ],
      "metadata": {
        "id": "65Khqc0G8ai4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation details:\n",
        "- First layer (the ```conv1``` in the table) is made up of  ```conv2d``` layer with kernel size 7, channel 64, and stride 2, (and set padding to 3) followed by a ```batchnorm2d``` layer.\n",
        "- ```conv2_x```, ```conv3_x```,  ```conv4_x```,  ```conv5_x``` layer consists of the bottleneck blocks, with different number of channels.\n",
        "- There should be a ```MaxPool2d``` layer before  ```conv2_x``` with kernel size 3 and stride 2, padding 1.\n",
        "- For ```conv2_x```, set stride to 1. For ```conv3_x```,  ```conv4_x```, ```conv5_x``` set stride to 2.\n",
        "- The output after ```conv5_x``` should pass average pooling, and a fully connected layer. Use ```torch.nn.AdaptiveAvgPool2d``` for average pooling and  ```nn.Linear``` for fully connected layer.\n",
        "- You do not have to implement softmax. (In training, we will use cross entropy loss)\n"
      ],
      "metadata": {
        "id": "33ojXRcnVlSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_blocks=[3,4,6,3], num_classes=10):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self,x):\n",
        "        # TODO\n"
      ],
      "metadata": {
        "id": "2ezB_Tdr-Vdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we finished building the model, we will implement optimizer and criterion for training. The details are as follows:\n",
        "- SGD optimizer (you can change and test with different parameters if you want). Use ```torch.optim.SGD``` for implementation.\n",
        "- cross entropy loss (as this is a classification task) Use ```torch.nn.CrossEntropyLoss``` for implementation."
      ],
      "metadata": {
        "id": "yfirQyCKefMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50()\n",
        "model.to(device)\n",
        "criterion = # TODO\n",
        "optimizer = # TODO"
      ],
      "metadata": {
        "id": "ZtKYNISkhGjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will move on to training our model with the data loaded above. For each training epoch, the following has to be done:\n",
        "\n",
        "- Get data (batches), load images and labels from the data. Use the ```trainloader``` in the skeleton code.\n",
        "- Set parameter gradients to zero. Use ```optimizer.zero_grad()```.\n",
        "- Feedforward data to get the model output.\n",
        "- Compute losses, and do backpropagation for optimization. Use ```loss.backward()``` and ```optimizer.step()```. \n",
        "\n",
        "You may add additional functions to print or plot the losses."
      ],
      "metadata": {
        "id": "WMlfBGQ9htIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGDC_bezLyvD"
      },
      "outputs": [],
      "source": [
        "for epoch in range(50): # you may change the number of epoches depending on the learning rate\n",
        "    # TODO\n",
        "     for idx, data in enumerate(trainloader):\n",
        "         # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the trained model with testing dataset. The overall process is similar with training the model, except that (1) the model is in evaluation mode, (2) the ```autograd``` is turned off."
      ],
      "metadata": {
        "id": "WKEak6VYiFb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # this changes the model's mode into evaluation mode \n",
        "with torch.no_grad(): # turn off autograd\n",
        "    # TODO"
      ],
      "metadata": {
        "id": "sNe8XxshlBce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result Report\n",
        "\n",
        "Once you finish the implementation, write the results in this colab file. The results should include:\n",
        "- results of the training loss per epoch (doesn't have to print/plot the results for every epoches. Printing/plotting within a certain frequency is fine)\n",
        "- results (losses) for evaluation\n",
        "- accuracy of classification in percentage for evaluation. Note: The accuracy percentage would not affect your grade. That is, regardless of the accuracy percentage value, you will get your grade if you measure and write on your report. \n",
        "\n",
        "You may do additional experiments (e.g., changing parameters, etc) but this will not affect your grade, which means there will be no points on additional experiments.  \n",
        "\n"
      ],
      "metadata": {
        "id": "TMg6XtpvmVqR"
      }
    }
  ]
}